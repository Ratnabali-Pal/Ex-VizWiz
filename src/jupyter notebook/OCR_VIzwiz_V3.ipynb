{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M0JhOGVpCiQ4"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._C import NoneType\n",
    "from ast import dump\n",
    "import numpy.linalg\n",
    "import numpy.linalg._umath_linalg\n",
    "#import numpy.linalg._umath_linalg._ilp64\n",
    "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
    "!pip install paddlepaddle-gpu\n",
    "!pip install paddleocr\n",
    "!pip install numpy==1.23.5\n",
    "!wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.0g-2ubuntu4_amd64.deb\n",
    "!sudo dpkg -i libssl1.1_1.1.0g-2ubuntu4_amd64.deb\n",
    "!pip install paddlepaddle\n",
    "!pip install \"paddleocr>=2.0.1\"\n",
    "!python3 setup.py bdist_wheel\n",
    "!pip3 install dist/paddleocr-x.x.x-py3-none-any.whl \n",
    "!pip install paddlepaddle paddleocr\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "#from paddleocr import PaddleOCR,draw_ocr\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg\n",
    " # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import torch\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "!pip install -U transformers[sentencepiece]\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbBaD5udYBDL"
   },
   "outputs": [],
   "source": [
    "#!python3 -m pip install numpy\n",
    "\n",
    "!pip install --upgrade transformers\n",
    "\n",
    "\n",
    "#!pip install numpy\n",
    "\n",
    "!pip install transformers==4.28.1\n",
    "from transformers import *\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from torch import tensor,argmax\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForQuestionAnswering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HecRZBzuZDSt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.28.1\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m648.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (1.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (2023.5.5)\n",
      "Requirement already satisfied: requests in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1)\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from transformers==4.28.1) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from requests->transformers==4.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from requests->transformers==4.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from requests->transformers==4.28.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/xim/anaconda3/envs/ratnabali/lib/python3.8/site-packages (from requests->transformers==4.28.1) (2023.5.7)\n",
      "Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.2\n",
      "    Uninstalling transformers-4.41.2:\n",
      "      Successfully uninstalled transformers-4.41.2\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to compare versions for numpy>=1.17: need=1.17 found=None. This is unusual. Consider reinstalling numpy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install transformers==4.28.1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m tokenizer_q \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrm8488/t5-base-finetuned-question-generation-ap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m model_q \u001b[38;5;241m=\u001b[39m AutoModelWithLMHead\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrm8488/t5-base-finetuned-question-generation-ap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ratnabali/lib/python3.8/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     logging,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     46\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ratnabali/lib/python3.8/site-packages/transformers/dependency_versions_check.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeps\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check dependency_versions_table.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ratnabali/lib/python3.8/site-packages/transformers/utils/versions.py:117\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry: pip install transformers -U or pip install -e \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.[dev]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre working with git main\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ratnabali/lib/python3.8/site-packages/transformers/utils/versions.py:111\u001b[0m, in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op, want_ver \u001b[38;5;129;01min\u001b[39;00m wanted\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 111\u001b[0m         \u001b[43m_compare_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgot_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ratnabali/lib/python3.8/site-packages/transformers/utils/versions.py:39\u001b[0m, in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compare_versions\u001b[39m(op, got_ver, want_ver, requirement, pkg, hint):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m got_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to compare versions for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: need=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwant_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is unusual. Consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reinstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version\u001b[38;5;241m.\u001b[39mparse(got_ver), version\u001b[38;5;241m.\u001b[39mparse(want_ver)):\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to compare versions for numpy>=1.17: need=1.17 found=None. This is unusual. Consider reinstalling numpy."
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer_q = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
    "model_q = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
    "model_a = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer_a = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02XquJOMHZhO"
   },
   "outputs": [],
   "source": [
    "!pip install pyimagesearch\n",
    "!pip install python3-pyimagesearch\n",
    "!pip install pyimagesearch\n",
    "!pip install tesseract\n",
    "!pip install ocr\n",
    "import sys, subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pytesseract\"])\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pytesseract as pt\n",
    "import os\n",
    "\n",
    "#from pyimagesearch.video_ocr import VideoOCROutputBuilder\n",
    "#from pyimagesearch.blur_detection import detect_blur_fft\n",
    "#from pyimagesearch.helpers import cleanup_text\n",
    "#from imutils.video import VideoStream\n",
    "#import pyimagesearch\n",
    "#from imutils.perspective import four_point_transform\n",
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import argparse\n",
    "#import imutils\n",
    "import time\n",
    "import cv2\n",
    "      \n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "def get_questions(context, max_length=64):\n",
    "    qns=[]\n",
    "    sentences=context.split('.')\n",
    "    for sentence in sentences[:-1]:\n",
    "        input_text = \"answer: %s  context: %s </s>\" % ('', sentence)\n",
    "        features = tokenizer_q([input_text], return_tensors='pt')\n",
    "\n",
    "        output = model_q.generate(input_ids=features['input_ids'],\n",
    "                          attention_mask=features['attention_mask'],\n",
    "                           max_length=max_length)\n",
    "        qns.append(tokenizer_q.decode(output[0]).replace('<pad> question: ','').replace('</s>',''))\n",
    "\n",
    "    return qns\n",
    "\n",
    "def answer_question(question, context):\n",
    "    input_ids = tokenizer_a.encode(question, context)\n",
    "    sep_index = input_ids.index(tokenizer_a.sep_token_id)\n",
    "    num_seg_a = sep_index + 1\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    outputs = model_a(tensor([input_ids]),\n",
    "                    token_type_ids=tensor([segment_ids]),\n",
    "                    return_dict=True)\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "    answer_start = argmax(start_scores)\n",
    "    answer_end = argmax(end_scores)\n",
    "    tokens = tokenizer_a.convert_ids_to_tokens(input_ids)\n",
    "    answer = tokens[answer_start]\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# get the path/directory\n",
    "folder_dir = \"/home/xim/Documents/Ratnabali/vizwizocr/\"\n",
    "with open('dataset/Annotations/Annotations/train.json', 'r+') as f:\n",
    "\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1t2her6hjGQB"
   },
   "outputs": [],
   "source": [
    "!pip install paddlepaddle\n",
    "!pip install pytesseract\n",
    "!pip install \"paddleocr>=2.0.6\"pip install paddlepaddle\n",
    "!pip install \"paddleocr>=2.0.6\"\n",
    "!pip install ocr\n",
    "!pip install numpy==1.21.6\n",
    "!pip install numpy==1.21.1\n",
    "for images in os.listdir(folder_dir):\n",
    "\n",
    "    # check if the image ends with png\n",
    "\n",
    "\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        print(images)\n",
    "        img_path =\"/home/xim/Documents/Ratnabali/vizwizocr/\"+images\n",
    "        result = ocr.ocr(img_path)\n",
    "        concat_output=\"\"\n",
    "        if(np.size(result[0])>1):\n",
    "          concat_output = \". \".join(row[1][0] for row in result[0])\n",
    "          context_q_a = concat_output\n",
    "          question_q_a=list(set(get_questions(context_q_a)))\n",
    "          answer_q_a=[]\n",
    "          for qn in question_q_a:\n",
    "              answer_q_a.append(answer_question(qn,context_q_a))\n",
    "          for i in range(len(question_q_a)):\n",
    "              #print('Qn.'+str(i+1)+'  '+question_q_a[i],sep='\\n')\n",
    "              #print('Ans : '+answer_q_a[i],sep='\\n',end='\\n\\n')\n",
    "              #data=data+'{\"image\":\"'+images+'\",'+ '\"question\":\"'+question_q_a[i]+'\",'+ '\"answers\": [      {        \"answer_confidence\": \"yes\", \"answer\": \"'+answer_q_a[i]+'\"}],'+'\"answer_type\": \"OCR_type\",\"answerable\": 1},'\n",
    "              image=images\n",
    "              question=question_q_a[i]\n",
    "              answer=answer_q_a[i]\n",
    "              answers=[{'answer_confidence': 'yes', 'answer': answer}]\n",
    "              new_data={'image': image, 'question': question, 'answers': answers, 'answer_type': 'OCR_type', 'answerable': 1}\n",
    "              data.append(new_data)\n",
    "\n",
    "\n",
    "with open('/dataset/Annotations/Annotations/train_new.json', mode='w+') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
